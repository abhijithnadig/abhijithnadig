{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijithnadig/abhijithnadig/blob/main/Spatial_Indexing_using_Hilbert_Curves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CS236 - Database Management Systems**\n",
        "\n",
        "## **Milestone 1**\n",
        "\n",
        "### **Name -** Abhijith A Nadig\n",
        "### **Student ID -** 862546804"
      ],
      "metadata": {
        "id": "UVRBkLgTk5pU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZljzC7T9J0T"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb6USLqN9Nfd"
      },
      "outputs": [],
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s26TCYgb9RPY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\"\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/spark-3.5.3-bin-hadoop3/python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaGarzv89TTC",
        "outputId": "3efbc7a1-ccac-4aec-cede-2f64632d322a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66lwt5aI9VK6",
        "outputId": "930c33d0-08f5-4cbf-cddc-36ed773bb939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-sedona[spark]\n",
            "  Downloading apache_sedona-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-sedona[spark]) (24.2.0)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-sedona[spark]) (2.0.6)\n",
            "Requirement already satisfied: pyspark>=2.3.0 in ./spark-3.5.3-bin-hadoop3/python (from apache-sedona[spark]) (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark>=2.3.0->apache-sedona[spark]) (0.10.9.7)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely>=1.7.0->apache-sedona[spark]) (1.26.4)\n",
            "Downloading apache_sedona-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/190.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/190.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-sedona\n",
            "Successfully installed apache-sedona-1.7.0\n",
            "Collecting hilbertcurve\n",
            "  Downloading hilbertcurve-2.0.5-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hilbertcurve) (1.26.4)\n",
            "Downloading hilbertcurve-2.0.5-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: hilbertcurve\n",
            "Successfully installed hilbertcurve-2.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-sedona[spark]\n",
        "!pip install hilbertcurve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sedona.core.SpatialRDD import PointRDD\n",
        "from sedona.core.spatialOperator import RangeQuery, KNNQuery\n",
        "from sedona.core.geom.envelope import Envelope\n",
        "from sedona.core.enums import GridType, IndexType, FileDataSplitter\n",
        "from shapely.geometry import Point\n",
        "from pyspark.storagelevel import StorageLevel\n",
        "from pyspark.sql.functions import col, expr, from_unixtime, lit, when\n",
        "from datetime import datetime\n",
        "from hilbertcurve.hilbertcurve import HilbertCurve\n",
        "from sedona.spark import *\n",
        "import time\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "eDnSAReXqvWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHuwm3pM9lfG"
      },
      "outputs": [],
      "source": [
        "config = SedonaContext.builder(). \\\n",
        "    config('spark.jars.packages',\n",
        "           'org.apache.sedona:sedona-spark-3.0_2.12:1.6.1,'\n",
        "           'org.datasyslab:geotools-wrapper:1.6.1-28.2'). \\\n",
        "    config('spark.jars.repositories', 'https://artifacts.unidata.ucar.edu/repository/unidata-all'). \\\n",
        "    getOrCreate()\n",
        "sedona = SedonaContext.create(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_PkEWsv9xSB"
      },
      "outputs": [],
      "source": [
        "# Define the file path to the input data\n",
        "file_path = '/content/2017-07-22_09-02-53.txt.gz'\n",
        "\n",
        "# Read the JSON file into a Sedona DataFrame\n",
        "t_data = sedona.read.json(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows with null coordinates and select the 'place.bounding_box' column, displaying the first 5 results without truncation\n",
        "t_data.filter(col('coordinates').isNull()).select('place.bounding_box').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8e84a3-11ca-4881-ff98-e07c490473a3",
        "id": "TkAtUnDJ-M15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------+\n",
            "|bounding_box                                                                                                   |\n",
            "+---------------------------------------------------------------------------------------------------------------+\n",
            "|{[[[-2.319934, 53.343623], [-2.319934, 53.570282], [-2.147026, 53.570282], [-2.147026, 53.343623]]], Polygon}  |\n",
            "|{[[[109.664659, 20.221264], [109.664659, 25.518608], [117.17479, 25.518608], [117.17479, 20.221264]]], Polygon}|\n",
            "|{[[[139.673228, 35.673404], [139.673228, 35.72991], [139.745133, 35.72991], [139.745133, 35.673404]]], Polygon}|\n",
            "|{[[[139.716598, 35.67375], [139.716598, 35.67375], [139.716598, 35.67375], [139.716598, 35.67375]]], Polygon}  |\n",
            "|{[[[72.64293, 15.606794], [72.64293, 22.029028], [80.899558, 22.029028], [80.899558, 15.606794]]], Polygon}    |\n",
            "+---------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSgoY5JcXTWt"
      },
      "outputs": [],
      "source": [
        "# Convert the Spark DataFrame 't_data' to a Pandas DataFrame for local processing\n",
        "df = t_data.toPandas()\n",
        "# Save the Pandas DataFrame to a CSV file named 'twitter.csv', excluding the index column\n",
        "df.to_csv('twitter.csv', index=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Handle longitude and latitude extraction\n",
        "data_cleaned = t_data.withColumn(\n",
        "    \"longitude\",\n",
        "    when(\n",
        "        col(\"coordinates\").isNotNull(),  # If 'coordinates' is available, use it\n",
        "        expr(\"coordinates.coordinates[0]\")\n",
        "    ).when(\n",
        "        col(\"place.bounding_box\").isNotNull(),  # If 'coordinates' is missing, use the center of 'bounding_box'\n",
        "        (expr(\"place.bounding_box.coordinates[0][0][0]\") + expr(\"place.bounding_box.coordinates[0][2][0]\")) / 2\n",
        "    ).otherwise(None)  # Set 'longitude' to null if both 'coordinates' and 'bounding_box' are missing\n",
        ").withColumn(\n",
        "    \"latitude\",\n",
        "    when(\n",
        "        col(\"coordinates\").isNotNull(),  # If 'coordinates' is available, use it\n",
        "        expr(\"coordinates.coordinates[1]\")\n",
        "    ).when(\n",
        "        col(\"place.bounding_box\").isNotNull(),  # If 'coordinates' is missing, use the center of 'bounding_box'\n",
        "        (expr(\"place.bounding_box.coordinates[0][0][1]\") + expr(\"place.bounding_box.coordinates[0][2][1]\")) / 2\n",
        "    ).otherwise(None)  # Set 'latitude' to null if both 'coordinates' and 'bounding_box' are missing\n",
        ")\n",
        "\n",
        "# Step 2: Create location column\n",
        "data_cleaned = data_cleaned.withColumn(\n",
        "    \"location\",\n",
        "    when(\n",
        "        col(\"longitude\").isNotNull() & col(\"latitude\").isNotNull(),  # Ensure both longitude and latitude are present\n",
        "        expr(\"ST_Point(longitude, latitude)\")  # Create a point location from longitude and latitude\n",
        "    ).otherwise(None)  # Set 'location' to null if either 'longitude' or 'latitude' is missing\n",
        ")\n",
        "\n",
        "# Step 3: Format the timestamp\n",
        "data_cleaned = data_cleaned.withColumn(\n",
        "    \"timestamp\",\n",
        "    from_unixtime(col(\"timestamp_ms\").cast(\"long\") / 1000).cast(\"timestamp\")  # Convert timestamp in milliseconds to a proper timestamp\n",
        ")\n",
        "\n",
        "# Step 4: Filter rows with valid location and timestamp\n",
        "data_cleaned = data_cleaned.filter(\n",
        "    col(\"location\").isNotNull() & col(\"timestamp\").isNotNull()  # Only keep rows with valid location and timestamp\n",
        ")\n",
        "\n",
        "# Step 5: Select only the desired columns (longitude, latitude, and timestamp)\n",
        "data_cleaned = data_cleaned.selectExpr(\n",
        "    \"longitude\", \"latitude\", \"timestamp\"  # Select only the relevant columns for further processing\n",
        ")\n",
        "\n",
        "# Step 6: Write to CSV\n",
        "output_path = \"/content/Outputs/Null_handled_Twitter_dataset\"  # Define the output path\n",
        "data_cleaned.write.mode(\"overwrite\").csv(output_path, header=False)  # Save the cleaned data to CSV (without header)\n"
      ],
      "metadata": {
        "id": "hIIxW6Ll2ICO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input location where the processed data is stored\n",
        "input_location = \"/content/Outputs/Null_handled_Twitter_dataset\"\n",
        "\n",
        "# Set the offset for longitude and latitude, assuming they start from Column 0 in the dataset\n",
        "offset = 0\n",
        "\n",
        "# Specify the file format as CSV using the FileDataSplitter enumeration\n",
        "splitter = FileDataSplitter.CSV\n",
        "\n",
        "# Flag indicating whether to carry other attributes (e.g., additional metadata) along with spatial data\n",
        "carry_other_attributes = True\n",
        "\n",
        "# Define the storage level for the PointRDD to be loaded into memory only\n",
        "level = StorageLevel.MEMORY_ONLY\n",
        "\n",
        "# Define the source coordinate system (EPSG 4326 for WGS 84)\n",
        "s_epsg = \"epsg:4326\"\n",
        "\n",
        "# Define the target coordinate system (EPSG 5070 for USA Contiguous Albers Equal Area Conic)\n",
        "t_epsg = \"epsg:5070\"\n",
        "\n",
        "# Create the PointRDD by reading the spatial data from the CSV file into Sedona's spatial RDD\n",
        "point_rdd = PointRDD(\n",
        "    sparkContext=sedona.sparkContext,  # SparkContext needed to initialize Sedona's operations\n",
        "    InputLocation=input_location,\n",
        "    Offset=offset,  # Column offset for longitude/latitude\n",
        "    splitter=splitter,  # File format for the data\n",
        "    carryInputData=carry_other_attributes  # Whether to retain additional non-spatial attributes\n",
        ")\n"
      ],
      "metadata": {
        "id": "F2fag4vlw_Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform spatial partitioning on the PointRDD using a specified strategy\n",
        "partitioning_strategy = GridType.QUADTREE  # Choose a partitioning strategy (QUADTREE, KDBTREE, etc.)\n",
        "point_rdd.spatialPartitioning(partitioning_strategy)  # Apply the chosen partitioning strategy to the PointRDD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsuf927LJxth",
        "outputId": "9952969e-dfbc-462e-99dd-48335189b47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to TRUE if a join query is going to be run after building the index, otherwise leave as False\n",
        "build_on_spatial_partitioned_rdd = False\n",
        "\n",
        "# Build an RTREE index on the PointRDD to optimize spatial queries\n",
        "point_rdd.buildIndex(IndexType.RTREE, build_on_spatial_partitioned_rdd)\n"
      ],
      "metadata": {
        "id": "hGv2zKtTMVF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bounding box coordinates for the spatial range query (xmin, ymin, xmax, ymax)\n",
        "xmin, ymin = -80.01, 50.52  # Minimum longitude and latitude\n",
        "xmax, ymax = -70.01, 40.01  # Maximum longitude and latitude\n",
        "\n",
        "# Define the time range for filtering results\n",
        "t1 = datetime.strptime(\"2017-07-22T09:08:22.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # Start of time range\n",
        "t2 = datetime.strptime(\"2017-07-22T09:10:29.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # End of time range\n",
        "\n",
        "# Create a spatial range query window using the defined bounding box coordinates\n",
        "query_window = Envelope(xmin, xmax, ymin, ymax)\n",
        "\n",
        "# Flag to specify whether to use an index for the query (RTREE or other types)\n",
        "index_used = True\n",
        "\n",
        "# Start timing the spatial range query execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Flag to consider boundary intersection when performing the range query\n",
        "consider_boundary = True  #\n",
        "\n",
        "# Perform the spatial range query on the PointRDD (point_rdd) using the query window (envelope)\n",
        "query_result = RangeQuery.SpatialRangeQuery(\n",
        "    point_rdd,  # The input PointRDD containing spatial data\n",
        "    query_window,  # The bounding box as the query window\n",
        "    consider_boundary,  # Flag to consider boundary intersections in query results\n",
        "    index_used  # Flag indicating whether to use an index for the query\n",
        ")\n",
        "\n",
        "# Filter the spatial query results by the specified time range\n",
        "filtered_results = query_result.filter(\n",
        "    lambda geom: t1 <= datetime.strptime(geom.getUserData(), \"%Y-%m-%dT%H:%M:%S.%fZ\") <= t2\n",
        "    # Convert the timestamp from the geometry's user data and check if it falls within the time range\n",
        ")\n",
        "\n",
        "# End timing the query execution\n",
        "end_time = time.time()\n",
        "\n",
        "# Output the total time taken to execute the query\n",
        "print(\"Query executed in\", end_time - start_time, \"seconds\")  # Print the elapsed time for the query\n",
        "\n",
        "# Extract and print the latitude and longitude (up to 3 decimal places) from geometry objects in a filtered dataset.\n",
        "print(\"Latitude         Longitude\")\n",
        "for result in filtered_results.collect():\n",
        "    geometry = result.geom  # Access the geometry object\n",
        "    latitude = round(geometry.y, 3)  # Extract and round latitude\n",
        "    longitude = round(geometry.x, 3)  # Extract and round longitude\n",
        "    print(\"{:<16} {}\".format(latitude, longitude))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FxXAlF7OYeK",
        "outputId": "fc849d3b-6092-4a05-b5cf-6558f4d0694a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query executed in 0.042449951171875 seconds\n",
            "Latitude         Longitude\n",
            "40.073           -74.724\n",
            "40.626           -74.244\n",
            "40.626           -74.244\n",
            "40.655           -73.949\n",
            "40.704           -73.709\n",
            "40.734           -74.185\n",
            "40.736           -74.172\n",
            "40.85            -73.849\n",
            "40.85            -73.849\n",
            "40.85            -73.849\n",
            "41.022           -74.679\n",
            "41.379           -72.868\n",
            "41.379           -72.868\n",
            "42.045           -71.114\n",
            "42.208           -71.687\n",
            "42.314           -71.089\n",
            "42.886           -78.868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bounding box coordinates for the spatial range query (xmin, ymin, xmax, ymax)\n",
        "xmin, ymin = -100.01, 10.01 # Minimum longitude and latitude\n",
        "xmax, ymax = -82.00, 38.50 # Maximum longitude and latitude\n",
        "\n",
        "# Define the time range for filtering results\n",
        "t1 = datetime.strptime(\"2017-07-22T09:08:22.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # Start of time range\n",
        "t2 = datetime.strptime(\"2017-07-22T09:10:29.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # End of time range\n",
        "\n",
        "# Create a spatial range query window using the defined bounding box coordinates\n",
        "query_window = Envelope(xmin, xmax, ymin, ymax)\n",
        "\n",
        "# Flag to specify whether to use an index for the query (RTREE or other types)\n",
        "index_used = True\n",
        "\n",
        "# Start timing the spatial range query execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Flag to consider boundary intersection when performing the range query\n",
        "consider_boundary = True  #\n",
        "\n",
        "# Perform the spatial range query on the PointRDD (point_rdd) using the query window (envelope)\n",
        "query_result = RangeQuery.SpatialRangeQuery(\n",
        "    point_rdd,  # The input PointRDD containing spatial data\n",
        "    query_window,  # The bounding box as the query window\n",
        "    consider_boundary,  # Flag to consider boundary intersections in query results\n",
        "    index_used  # Flag indicating whether to use an index for the query\n",
        ")\n",
        "\n",
        "# Filter the spatial query results by the specified time range\n",
        "filtered_results = query_result.filter(\n",
        "    lambda geom: t1 <= datetime.strptime(geom.getUserData(), \"%Y-%m-%dT%H:%M:%S.%fZ\") <= t2\n",
        "    # Convert the timestamp from the geometry's user data and check if it falls within the time range\n",
        ")\n",
        "\n",
        "# End timing the query execution\n",
        "end_time = time.time()\n",
        "\n",
        "# Output the total time taken to execute the query\n",
        "print(\"Query executed in\", end_time - start_time, \"seconds\")  # Print the elapsed time for the query\n",
        "\n",
        "# Extract and print the latitude and longitude (up to 3 decimal places) from geometry objects in a filtered dataset.\n",
        "print(\"Latitude         Longitude\")\n",
        "for result in filtered_results.collect():\n",
        "    geometry = result.geom  # Access the geometry object\n",
        "    latitude = round(geometry.y, 3)  # Extract and round latitude\n",
        "    longitude = round(geometry.x, 3)  # Extract and round longitude\n",
        "    print(\"{:<16} {}\".format(latitude, longitude))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCrnxATWXEHc",
        "outputId": "e9617e3d-3e55-4a87-8902-42ed2da1e945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query executed in 0.010615348815917969 seconds\n",
            "Latitude         Longitude\n",
            "19.032           -98.154\n",
            "19.119           -98.261\n",
            "19.433           -99.133\n",
            "16.922           -96.364\n",
            "19.184           -96.229\n",
            "22.283           -97.823\n",
            "20.941           -89.624\n",
            "27.462           -82.579\n",
            "27.699           -83.804\n",
            "27.699           -83.804\n",
            "27.699           -83.804\n",
            "26.112           -97.492\n",
            "26.177           -98.0\n",
            "26.3             -97.926\n",
            "26.315           -98.307\n",
            "27.737           -97.432\n",
            "27.798           -97.09\n",
            "29.111           -97.286\n",
            "29.288           -94.823\n",
            "29.38            -94.968\n",
            "29.548           -95.327\n",
            "27.699           -83.804\n",
            "27.71            -82.321\n",
            "27.997           -82.443\n",
            "29.763           -95.383\n",
            "29.418           -98.541\n",
            "29.418           -98.541\n",
            "29.418           -98.541\n",
            "29.418           -98.541\n",
            "29.418           -98.541\n",
            "29.418           -98.541\n",
            "29.838           -95.446\n",
            "29.838           -95.446\n",
            "29.838           -95.446\n",
            "29.902           -93.956\n",
            "29.983           -90.011\n",
            "30.426           -89.069\n",
            "30.476           -84.266\n",
            "30.684           -88.162\n",
            "32.231           -90.158\n",
            "32.521           -92.077\n",
            "32.543           -96.856\n",
            "32.656           -97.011\n",
            "32.576           -86.681\n",
            "32.702           -97.136\n",
            "32.702           -97.136\n",
            "32.678           -83.174\n",
            "32.678           -83.174\n",
            "32.678           -83.174\n",
            "32.82            -96.762\n",
            "32.846           -97.095\n",
            "32.898           -97.041\n",
            "32.908           -96.622\n",
            "33.197           -87.533\n",
            "33.753           -84.261\n",
            "33.767           -84.433\n",
            "33.875           -84.315\n",
            "33.943           -84.352\n",
            "34.752           -92.131\n",
            "35.134           -89.922\n",
            "36.039           -95.77\n",
            "36.294           -95.31\n",
            "37.684           -97.344\n",
            "38.196           -85.722\n",
            "38.34            -85.588\n",
            "38.498           -98.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bounding box coordinates for the spatial range query (xmin, ymin, xmax, ymax)\n",
        "xmin, ymin = 99.01, 10.01 # Minimum longitude and latitude\n",
        "xmax, ymax = 72.00, 38.50 # Maximum longitude and latitude\n",
        "\n",
        "# Define the time range for filtering results\n",
        "t1 = datetime.strptime(\"2017-07-22T09:08:22.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # Start of time range\n",
        "t2 = datetime.strptime(\"2017-07-22T09:10:29.000Z\", \"%Y-%m-%dT%H:%M:%S.%fZ\")  # End of time range\n",
        "\n",
        "# Create a spatial range query window using the defined bounding box coordinates\n",
        "query_window = Envelope(xmin, xmax, ymin, ymax)\n",
        "\n",
        "# Flag to specify whether to use an index for the query (RTREE or other types)\n",
        "index_used = True\n",
        "\n",
        "# Start timing the spatial range query execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Flag to consider boundary intersection when performing the range query\n",
        "consider_boundary = True  #\n",
        "\n",
        "# Perform the spatial range query on the PointRDD (point_rdd) using the query window (envelope)\n",
        "query_result = RangeQuery.SpatialRangeQuery(\n",
        "    point_rdd,  # The input PointRDD containing spatial data\n",
        "    query_window,  # The bounding box as the query window\n",
        "    consider_boundary,  # Flag to consider boundary intersections in query results\n",
        "    index_used  # Flag indicating whether to use an index for the query\n",
        ")\n",
        "\n",
        "# Filter the spatial query results by the specified time range\n",
        "filtered_results = query_result.filter(\n",
        "    lambda geom: t1 <= datetime.strptime(geom.getUserData(), \"%Y-%m-%dT%H:%M:%S.%fZ\") <= t2\n",
        "    # Convert the timestamp from the geometry's user data and check if it falls within the time range\n",
        ")\n",
        "\n",
        "# End timing the query execution\n",
        "end_time = time.time()\n",
        "\n",
        "# Output the total time taken to execute the query\n",
        "print(\"Query executed in\", end_time - start_time, \"seconds\")  # Print the elapsed time for the query\n",
        "\n",
        "# Extract and print the latitude and longitude (up to 3 decimal places) from geometry objects in a filtered dataset.\n",
        "print(\"Latitude         Longitude\")\n",
        "for result in filtered_results.collect():\n",
        "    geometry = result.geom  # Access the geometry object\n",
        "    latitude = round(geometry.y, 3)  # Extract and round latitude\n",
        "    longitude = round(geometry.x, 3)  # Extract and round longitude\n",
        "    print(\"{:<16} {}\".format(latitude, longitude))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grTxPc-BXYEq",
        "outputId": "bed192ae-1870-4f7a-87a8-ebd7bb11e068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query executed in 0.012325525283813477 seconds\n",
            "Latitude         Longitude\n",
            "10.543           76.137\n",
            "12.923           77.558\n",
            "12.939           80.162\n",
            "12.972           77.595\n",
            "13.024           80.262\n",
            "15.276           74.006\n",
            "15.4             74.005\n",
            "18.704           98.931\n",
            "18.508           73.91\n",
            "18.772           98.999\n",
            "18.784           98.953\n",
            "18.792           98.969\n",
            "19.097           73.036\n",
            "19.174           72.874\n",
            "19.174           72.874\n",
            "19.174           72.874\n",
            "19.174           72.874\n",
            "19.174           72.874\n",
            "19.939           82.584\n",
            "21.171           72.789\n",
            "21.171           72.789\n",
            "22.954           73.335\n",
            "23.014           72.57\n",
            "22.613           88.352\n",
            "22.613           88.352\n",
            "22.613           88.352\n",
            "22.613           88.352\n",
            "22.613           88.352\n",
            "24.459           73.826\n",
            "25.373           82.933\n",
            "25.374           78.732\n",
            "26.628           73.878\n",
            "26.825           80.884\n",
            "26.91            75.748\n",
            "27.014           80.824\n",
            "28.331           77.351\n",
            "28.369           76.975\n",
            "28.391           84.133\n",
            "28.391           84.133\n",
            "28.546           77.499\n",
            "28.546           77.499\n",
            "28.569           77.232\n",
            "28.638           77.095\n",
            "28.638           77.095\n",
            "28.774           77.423\n",
            "28.954           77.267\n",
            "29.573           74.92\n",
            "30.864           72.355\n",
            "30.864           72.355\n",
            "30.864           72.355\n",
            "30.864           72.355\n",
            "31.532           74.358\n",
            "32.329           75.639\n",
            "26.26            91.56\n",
            "33.865           75.152\n",
            "34.063           72.099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Milestone 2**\n",
        "\n",
        "## **2.1 Obtain Hilbert Numbers**"
      ],
      "metadata": {
        "id": "X6KLXRgD4Kin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters for the Hilbert Curve:\n",
        "p_val = 10\n",
        "dim = 2\n",
        "\n",
        "# Create a Hilbert curve instance with the specified parameters.\n",
        "hilbert_instance = HilbertCurve(p_val, dim)\n",
        "\n",
        "# Define the spatial bounds for the coordinate normalization.\n",
        "x_min, y_min = -180, -90\n",
        "x_max, y_max = 180, 90\n",
        "\n",
        "# Function to compute the Hilbert index for a given point\n",
        "def compute_hilbert_index(pt):\n",
        "    lon_val = pt.geom.x\n",
        "    lat_val = pt.geom.y\n",
        "\n",
        "    # Normalize the longitude and latitude values to fit within the Hilbert curve's grid range\n",
        "    x_norm = int((lon_val - x_min) / (x_max - x_min) * (2**p_val - 1))\n",
        "    y_norm = int((lat_val - y_min) / (y_max - y_min) * (2**p_val - 1))\n",
        "\n",
        "    # Compute the Hilbert index for the normalized coordinates\n",
        "    hilbert_idx = hilbert_instance.distance_from_point([x_norm, y_norm])\n",
        "\n",
        "    # Retrieve the user-defined data associated with the point\n",
        "    ts = pt.getUserData()\n",
        "\n",
        "    # Return the Hilbert index and timestamp as a formatted string\n",
        "    return str(hilbert_idx) + \",\" + str(ts)\n",
        "\n",
        "# Filter the RDD to retain only valid points with non-null geometries and user data.\n",
        "valid_points_rdd = point_rdd.rawSpatialRDD.filter(\n",
        "    lambda pt: pt.geom is not None and pt.getUserData() is not None\n",
        ")\n",
        "\n",
        "# Map the valid points to compute their Hilbert indices and include associated user data.\n",
        "hilbert_mapped_data = valid_points_rdd.map(compute_hilbert_index)\n",
        "\n",
        "# Print the first 5 results of the computed Hilbert indices and associated data.\n",
        "print(\"Results:\")\n",
        "print(hilbert_mapped_data.take(5))\n",
        "\n",
        "# Remove any existing output directory to prevent errors when saving the new data.\n",
        "!rm -rf {output_dir}\n",
        "\n",
        "# Specify the directory for saving the mapped Hilbert data.\n",
        "output_dir = \"/content/hilbert_data\"\n",
        "\n",
        "# Save the computed Hilbert indices and associated data as a text file in the specified directory.\n",
        "hilbert_mapped_data.saveAsTextFile(output_dir)\n",
        "\n",
        "# Confirm that the data has been successfully saved.\n",
        "print(\"Data saved to: \" + output_dir)\n"
      ],
      "metadata": {
        "id": "fnaoWdU0nxqL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc885b6-d6d2-4e3c-b86c-9c1cedf704fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "['457532,2017-07-22T09:02:53.000Z', '751701,2017-07-22T09:02:53.000Z', '505164,2017-07-22T09:02:53.000Z', '749570,2017-07-22T09:02:52.000Z', '733342,2017-07-22T09:02:53.000Z']\n",
            "Data saved to: /content/hilbert_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 In Apache Sedona, spatially partition the datasets (using the new 2D data) into the worker nodes, and build an R-Tree index on each data partition.**"
      ],
      "metadata": {
        "id": "i1qfGwnQbigY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sedona.core.enums import GridType, IndexType\n",
        "\n",
        "# Spatially partition the datasets into worker nodes.\n",
        "point_rdd.spatialPartitioning(GridType.QUADTREE)\n",
        "\n",
        "# Build an R-Tree index on each partition.\n",
        "point_rdd.buildIndex(IndexType.RTREE, True)\n",
        "\n",
        "# Specify the directory for saving the partitioned and indexed data\n",
        "output_dir = \"/content/spatially_partitioned_indexed_data\"\n",
        "\n",
        "# Remove the output directory if it already exists to avoid conflicts\n",
        "!rm -rf {output_dir}\n",
        "\n",
        "# Save the spatially partitioned and indexed data\n",
        "point_rdd.rawSpatialRDD.saveAsTextFile(output_dir)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Spatially partitioned and indexed data saved to: \" + output_dir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMpEE-8k_8zi",
        "outputId": "9b40f66f-dd64-44fc-9361-72006f03bc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spatially partitioned and indexed data saved to: /content/spatially_partitioned_indexed_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 Run Range query with time filter on the data**"
      ],
      "metadata": {
        "id": "AxuoZAJ8jatx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to convert ISO 8601 timestamp to Unix time\n",
        "def parse_timestamp_to_unix(ts):\n",
        "    try:\n",
        "        return int(datetime.strptime(ts, \"%Y-%m-%dT%H:%M:%S.%fZ\").timestamp())\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# Function to process range queries\n",
        "def process_range_query(query, hilbert_instance, p_val, x_min, x_max, y_min, y_max, hilbert_mapped_data):\n",
        "    (x1, y1), (x2, y2), (t1, t2) = query\n",
        "\n",
        "    # Convert t1 and t2 to Unix timestamps\n",
        "    t1_unix = parse_timestamp_to_unix(t1)\n",
        "    t2_unix = parse_timestamp_to_unix(t2)\n",
        "\n",
        "    # Step 1: Enlarge the query range\n",
        "    u1 = int((x1 - x_min) / (x_max - x_min) * (2**p_val - 1))\n",
        "    v1 = int((y1 - y_min) / (y_max - y_min) * (2**p_val - 1))\n",
        "    u2 = int((x2 - x_min) / (x_max - x_min) * (2**p_val - 1))\n",
        "    v2 = int((y2 - y_min) / (y_max - y_min) * (2**p_val - 1))\n",
        "\n",
        "    # Ensure corners align to the smallest enclosing grid rectangle\n",
        "    u1, v1, u2, v2 = map(lambda val: max(0, min(val, 2**p_val - 1)), [u1, v1, u2, v2])\n",
        "\n",
        "    # Step 2: Compute Hilbert indices for the enlarged rectangle\n",
        "    Hu1v1 = hilbert_instance.distance_from_point([u1, v1])\n",
        "    Hu2v2 = hilbert_instance.distance_from_point([u2, v2])\n",
        "\n",
        "    # Retrieve all points with Hilbert index in the range [Hu1v1, Hu2v2] and temporal range [t1_unix, t2_unix]\n",
        "    start_time = time.time()\n",
        "    filtered_data = hilbert_mapped_data.filter(\n",
        "        lambda row: (\n",
        "            Hu1v1 <= int(row.split(\",\")[0]) <= Hu2v2 and\n",
        "            t1_unix <= parse_timestamp_to_unix(row.split(\",\")[1]) <= t2_unix\n",
        "        )\n",
        "    ).collect()\n",
        "    filter_end_time = time.time()\n",
        "\n",
        "    # Refinement Step: Convert to (x, y, t) triples and return only points within the original range\n",
        "    refined_results = []\n",
        "    for data in filtered_data:\n",
        "        hilbert_idx, timestamp = data.split(\",\")\n",
        "        hilbert_idx = int(hilbert_idx)\n",
        "        timestamp = parse_timestamp_to_unix(timestamp)\n",
        "        x, y = hilbert_instance.point_from_distance(hilbert_idx)\n",
        "        x = x / (2**p_val - 1) * (x_max - x_min) + x_min\n",
        "        y = y / (2**p_val - 1) * (y_max - y_min) + y_min\n",
        "        if x1 <= x <= x2 and y1 <= y <= y2 and t1_unix <= timestamp <= t2_unix:\n",
        "            refined_results.append((x, y, timestamp))\n",
        "\n",
        "    refinement_end_time = time.time()\n",
        "\n",
        "    # Calculate metrics\n",
        "    total_points_retrieved = len(filtered_data)\n",
        "    spurious_points = total_points_retrieved - len(refined_results)\n",
        "    spurious_fraction = spurious_points / total_points_retrieved if total_points_retrieved > 0 else 0\n",
        "    print(\"Spurious Points: \", spurious_points)\n",
        "    print(\"Total Points Retrieved: \", total_points_retrieved)\n",
        "    print(\"Spurious Fraction: \", spurious_fraction)\n",
        "    print(\"Filter Time: \",filter_end_time - start_time)\n",
        "    print(\"Refinement Time: \", refinement_end_time - filter_end_time)\n",
        "    print(\"Total Time: \", refinement_end_time - start_time)\n",
        "\n",
        "    return {\n",
        "        \"results\": refined_results\n",
        "        }\n",
        "\n",
        "\n",
        "# Example Query\n",
        "query = [(-100, 30), (-90, 40), (\"2017-07-22T09:06:00.000Z\", \"2017-07-22T09:07:00.000Z\")]\n",
        "\n",
        "# Process the query\n",
        "result = process_range_query(query, hilbert_instance, p_val, x_min, x_max, y_min, y_max, hilbert_mapped_data)\n",
        "\n",
        "# Display results and metrics\n",
        "print(\"Query Results:\")\n",
        "print(result[\"results\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgWnvTfxC9VO",
        "outputId": "a53c3be7-446c-4891-e5d1-1a4957b11175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spurious Points:  41\n",
            "Total Points Retrieved:  70\n",
            "Spurious Fraction:  0.5857142857142857\n",
            "Filter Time:  2.4094042778015137\n",
            "Refinement Time:  0.0034723281860351562\n",
            "Total Time:  2.412876605987549\n",
            "Query Results:\n",
            "[(-90.26392961876833, 32.111436950146626, 1500714360), (-98.0058651026393, 30.175953079178882, 1500714362), (-92.37536656891496, 32.46334310850439, 1500714363), (-92.37536656891496, 34.750733137829926, 1500714365), (-96.95014662756599, 32.81524926686217, 1500714369), (-97.30205278592376, 32.63929618768327, 1500714369), (-94.83870967741935, 39.67741935483872, 1500714373), (-97.30205278592376, 32.63929618768327, 1500714375), (-96.95014662756599, 32.46334310850439, 1500714376), (-98.0058651026393, 30.175953079178882, 1500714376), (-97.65395894428153, 31.055718475073306, 1500714378), (-96.95014662756599, 32.81524926686217, 1500714379), (-97.30205278592376, 36.686217008797655, 1500714381), (-96.59824046920822, 32.99120234604105, 1500714383), (-90.26392961876833, 32.111436950146626, 1500714389), (-94.83870967741935, 38.97360703812316, 1500714390), (-97.30205278592376, 32.63929618768327, 1500714391), (-96.95014662756599, 33.51906158357771, 1500714391), (-97.30205278592376, 32.81524926686217, 1500714395), (-91.67155425219941, 30.879765395894424, 1500714397), (-97.30205278592376, 32.63929618768327, 1500714397), (-97.65395894428153, 35.45454545454547, 1500714398), (-92.37536656891496, 30.175953079178882, 1500714402), (-94.1348973607038, 32.28739002932551, 1500714408), (-96.95014662756599, 32.81524926686217, 1500714411), (-90.96774193548387, 30.527859237536646, 1500714412), (-90.26392961876833, 30.175953079178882, 1500714413), (-97.65395894428153, 37.56598240469209, 1500714416), (-96.95014662756599, 32.81524926686217, 1500714417)]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}